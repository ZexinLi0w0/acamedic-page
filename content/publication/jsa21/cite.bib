@article{LI2021101936,
title = {Efficient algorithms for task mapping on heterogeneous CPU/GPU platforms for fast completion time},
journal = {Journal of Systems Architecture},
volume = {114},
pages = {101936},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2020.101936},
url = {https://www.sciencedirect.com/science/article/pii/S1383762120301934},
author = {Zexin Li and Yuqun Zhang and Ao Ding and Husheng Zhou and Cong Liu},
keywords = {GPU, Heterogeneous scheduling, Data-size-based prediction, Neural network runtime acceleration},
abstract = {In GPU-based embedded systems, the problem of computation and data mapping for multiple applications while minimizing the completion time is quite challenging due to large size of the policy space. To achieve fast competition time, a fine-grain mapping framework that explores a set of critical factors is needed for heterogeneous embedded systems. In this paper, we present a theoretical framework that yields a sub-optimal solution via three practical mapping algorithms with low time complexity. We evaluate such algorithms upon StarPU with a large set of popular benchmarks. Experimental results demonstrate that algorithms proposed by the original EMSOFT paper can achieve up to 30% faster completion time compared to state-of-the-art mapping techniques, and can perform consistently well across different workloads. We further extend such algorithms to minimize the completion time and enhance the runtime performance of complex heterogeneous applications under resource-limited infrastructure. We also extend the evaluation by deploying StarPU under multiple setups with an additional benchmark testing suite for simulating real-world runtime neural networks. Experimental results demonstrate that our extended algorithm can achieve much faster completion time (averagely 30% to 37% under multiple resource-constraint scenarios) compared to the state-of-the-art mapping techniques.}
}